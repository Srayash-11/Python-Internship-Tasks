{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO0AdR5EGS4AGzQMbrH7Cpz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srayash-11/Python-Internship-Tasks/blob/main/Task3_House_Price_Prediction/House_Price_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# This is the \"Permanent\" way. Replace the link below with your 'Raw' link from GitHub\n",
        "csv_url = 'https://raw.githubusercontent.com/Srayash-11/Python-Internship-Tasks/refs/heads/main/Task3_House_Price_Prediction/Bengaluru_House_Data.csv'\n",
        "\n",
        "try:\n",
        "    # Python will now download the data directly from GitHub every time you run it!\n",
        "    df = pd.read_csv(csv_url)\n",
        "    print(\" Success! Data loaded directly from GitHub.\")\n",
        "    display(df.head())\n",
        "except Exception as e:\n",
        "    print(f\" Error: Could not load the file. Check your link! {e}\")"
      ],
      "metadata": {
        "id": "HpSbHPwyJFWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We are telling the computer: \"Only keep these 5 columns\"\n",
        "df = df[['location', 'size', 'total_sqft', 'bath', 'price']]\n",
        "\n",
        "# Let's see how many rows we have total\n",
        "print(f\"We have {len(df)} rows of data.\")\n",
        "df.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RiFWlvbeHZLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This removes any row that has a missing value\n",
        "df = df.dropna()\n",
        "\n",
        "print(\"Step 4: All empty rows have been removed.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HBJMz5Z9Hg4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We take the 'size' column (e.g., \"2 BHK\"), split it at the space, and take the first part\n",
        "df['bhk'] = df['size'].apply(lambda x: int(x.split(' ')[0]))\n",
        "\n",
        "# Now we can drop the old 'size' column because we have the 'bhk' column\n",
        "df = df.drop('size', axis='columns')\n",
        "\n",
        "print(\"Step 5: Converted text sizes into a clean 'bhk' number column.\")\n",
        "df.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DDZRYSdCHjAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. We define a small \"rule\" (function) to handle the text\n",
        "def convert_sqft_to_num(x):\n",
        "    tokens = x.split('-') # Look for the dash '-'\n",
        "    if len(tokens) == 2: # If there are two numbers with a dash\n",
        "        # Take the average of the two numbers\n",
        "        return (float(tokens[0]) + float(tokens[1]))/2\n",
        "    try:\n",
        "        # If it's already a single number, just turn it into a float\n",
        "        return float(x)\n",
        "    except:\n",
        "        # If it's something weird like '1Perch', just ignore it\n",
        "        return None\n",
        "\n",
        "# 2. Apply this rule to every row in the 'total_sqft' column\n",
        "df['total_sqft'] = df['total_sqft'].apply(convert_sqft_to_num)\n",
        "\n",
        "# 3. Drop any rows that couldn't be converted (the 'None' values)\n",
        "df = df.dropna()\n",
        "\n",
        "print(\"Step 6: All square footage values are now clean numbers!\")\n",
        "df.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "S7-lXABZIRBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column by dividing price by total_sqft\n",
        "# Note: Price in this dataset is in Lakhs, so we multiply by 100,000\n",
        "df['price_per_sqft'] = (df['price'] * 100000) / df['total_sqft']\n",
        "\n",
        "print(\"Step 7: Added 'price_per_sqft' to help us find errors in the data.\")\n",
        "df.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "03FCgIsuITd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We only keep rows where (Total Sqft / BHK) is at least 300\n",
        "df = df[~(df.total_sqft/df.bhk < 300)]\n",
        "\n",
        "print(f\"Step 8: Removed rows where the house was too small for the number of bedrooms.\")\n",
        "print(f\"Current rows: {len(df)}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JOoiBvuqJLOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Ensure price_per_sqft is calculated before removing outliers\n",
        "df['price_per_sqft'] = (df['price'] * 100000) / df['total_sqft']\n",
        "\n",
        "def remove_pps_outliers(df):\n",
        "    df_out = pd.DataFrame()\n",
        "    for key, subdf in df.groupby('location'):\n",
        "        m = np.mean(subdf.price_per_sqft) # Average price in that location\n",
        "        st = np.std(subdf.price_per_sqft) # Standard deviation\n",
        "        # Keep data within 1 standard deviation of the mean\n",
        "        reduced_df = subdf[(subdf.price_per_sqft > (m-st)) & (subdf.price_per_sqft <= (m+st))]\n",
        "        df_out = pd.concat([df_out, reduced_df], ignore_index=True)\n",
        "    return df_out\n",
        "\n",
        "df = remove_pps_outliers(df)\n",
        "print(f\"Step 9: Removed price outliers based on location.\")\n",
        "print(f\"Final clean rows: {len(df)}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jhv-_EAtJS08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columns that are text or just helped us clean the data\n",
        "df_final = df.drop(['location', 'price_per_sqft'], axis='columns')\n",
        "\n",
        "print(\"Step 10: Final data structure ready for AI training!\")\n",
        "df_final.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YAcGD1E5KMv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We create a final table with only the numbers we need\n",
        "# X is our 'Features' (The questions)\n",
        "# y is our 'Target' (The answer we want to predict)\n",
        "\n",
        "X = df[['total_sqft', 'bath', 'bhk']]\n",
        "y = df['price']\n",
        "\n",
        "print(\"Step 11: Features and Target variables are separated.\")\n",
        "X.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "t5ORO-xiKdzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# We use 80% for training (teaching) and 20% for testing (the final exam)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
        "\n",
        "print(f\"Step 12: Data Split! Training on {len(X_train)} rows and testing on {len(X_test)} rows.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rrilQK7lKqSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 1. Initialize the model\n",
        "lr_clf = LinearRegression()\n",
        "\n",
        "# 2. Train the model (this is where it 'learns' the patterns)\n",
        "lr_clf.fit(X_train, y_train)\n",
        "\n",
        "# 3. Check the 'Score' (Accuracy)\n",
        "accuracy = lr_clf.score(X_test, y_test)\n",
        "print(f\"Step 13: Model Training Complete! Accuracy Score: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lab-wQWgKvy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. We create a tiny table (DataFrame) with labels so the AI isn't confused\n",
        "my_house = pd.DataFrame([[2000, 3, 3]], columns=['total_sqft', 'bath', 'bhk'])\n",
        "\n",
        "# 2. Now we predict using that labeled table\n",
        "predicted_price = lr_clf.predict(my_house)\n",
        "\n",
        "print(f\"--- Final Prediction ---\")\n",
        "print(f\"House Specs: 2000 Sqft, 3 BHK, 3 Bathrooms\")\n",
        "print(f\"Predicted Market Price: â‚¹{predicted_price[0]:.2f} Lakhs\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "G2q5Jj4mLm9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Generate predictions for our 'Test' set (the exam)\n",
        "y_pred = lr_clf.predict(X_test)\n",
        "\n",
        "# 2. Create a figure with two side-by-side charts\n",
        "plt.figure(figsize=(16, 6))\n",
        "\n",
        "# --- Chart A: Actual vs Predicted ---\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(y_test, y_pred, alpha=0.5, color='teal')\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', lw=2) # The \"Perfect\" line\n",
        "plt.title('How Accurate is the AI?\\n(Actual vs Predicted Prices)', fontsize=14)\n",
        "plt.xlabel('Actual Price (Lakhs)', fontsize=12)\n",
        "plt.ylabel('AI Predicted Price (Lakhs)', fontsize=12)\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "# --- Chart B: Feature Correlation ---\n",
        "plt.subplot(1, 2, 2)\n",
        "# We use df_final because it has the clean numbers for our features\n",
        "correlation_matrix = df_final.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='YlGnBu', fmt=\".2f\")\n",
        "plt.title('What Drives the Price?\\n(Correlation Heatmap)', fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\" Visuals Generated! You can right-click the images to 'Save Image As' for your report.\")"
      ],
      "metadata": {
        "id": "Z-Nc3CeSMyxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Final Insights & Observations\n",
        "* **Model Reliability:** The Linear Regression model effectively captured the trend that house prices in Bengaluru increase proportionally with square footage.\n",
        "* **Feature Importance:** During analysis, it was observed that the number of bathrooms and BHK are secondary to the total area (sqft) in determining the final price.\n",
        "* **Data Quality:** Removing outliers was a critical step; without it, the model's accuracy was significantly lower due to unrealistic data points in the original Kaggle set.\n",
        "* **Future Scope:** This project can be expanded by adding \"Location Encoding\" to predict prices more accurately for specific areas like Whitefield or Indiranagar."
      ],
      "metadata": {
        "id": "C70OhvuOEz9k"
      }
    }
  ]
}